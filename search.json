[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am an AI Developer Relations Engineer at Sieve, a Y Combinator-backed startup based in San Francisco. Sieve offers API tools for video AI, including a platform for deploying models, a Python library with ready-to-use AI models, and applications built for different use cases.\nI hold a Ph.D.¬†from the Indian Institute of Science (IISc), Bangalore, where I conducted research at the LEAP lab under Prof.¬†Sriram Ganapathy. Previously, I worked as a research engineer in Image Processing at Tata Research Development and Design Center (TRDDC), Pune.\nMy academic background includes an MTech in System Science and Automation (now ‚ÄòArtificial Intelligence‚Äô) from IISc and a BTech in Electronics and Communication from the College of Engineering, Trivandrum (CET)."
  },
  {
    "objectID": "ml-notes/ml_basics.html",
    "href": "ml-notes/ml_basics.html",
    "title": "akshara soman",
    "section": "",
    "text": "Expand All\n  Collapse All\n\n\n\n\n\n\n\n\n\n{{QUESTION}}\n\n{{CORE_ANSWER}}\nOne-line answer:\n{{ONE_LINE}}\nCommon trap:\n{{TRAP}}"
  },
  {
    "objectID": "ml-notes/index.html",
    "href": "ml-notes/index.html",
    "title": "ML ‚Äî Rolling Notes",
    "section": "",
    "text": "Expand All\n  Collapse All"
  },
  {
    "objectID": "ml-notes/index.html#topics",
    "href": "ml-notes/index.html#topics",
    "title": "ML ‚Äî Rolling Notes",
    "section": "üìö Topics",
    "text": "üìö Topics\nEach topic contains click-to-expand questions, optimized for quick revision.\n\nAttention & Transformers\nOptimization & Training\nCNNs & Computer Vision\nML Basics\n\nLast updated: January 15, 2026"
  },
  {
    "objectID": "ml-notes/attention.html",
    "href": "ml-notes/attention.html",
    "title": "Attention & Transformers ‚Äî Interview Q&A",
    "section": "",
    "text": "Expand All\n  Collapse All"
  },
  {
    "objectID": "ml-notes/attention.html#self-attention",
    "href": "ml-notes/attention.html#self-attention",
    "title": "Attention & Transformers ‚Äî Interview Q&A",
    "section": "Self-Attention",
    "text": "Self-Attention\n\n\nWhat is self-attention?\n\nSelf-attention allows each token in a sequence to weigh the relevance of all other tokens when computing its representation.\nOne-line:\nSelf-attention lets each token dynamically focus on other tokens to model global context.\nTrap:\nConfusing self-attention with cross-attention.\n\n\n\nWhy is scaling used in dot-product attention?\n\nScaling by ‚àöd‚Çñ prevents large dot-product values from pushing the softmax into saturation, which stabilizes gradients.\nOne-line:\nScaling avoids softmax saturation and stabilizes training."
  },
  {
    "objectID": "ml-notes/attention.html#multi-head-attention",
    "href": "ml-notes/attention.html#multi-head-attention",
    "title": "Attention & Transformers ‚Äî Interview Q&A",
    "section": "Multi-Head Attention",
    "text": "Multi-Head Attention\n\n\nWhy use multiple attention heads?\n\nMultiple heads allow the model to attend to different representation subspaces and capture diverse relationships in parallel.\nOne-line:\nMulti-head attention learns different relationships simultaneously."
  },
  {
    "objectID": "posts/002_chatbot/in_keyaspects_chatbot.html",
    "href": "posts/002_chatbot/in_keyaspects_chatbot.html",
    "title": "Key Aspects of Building a Chatbot",
    "section": "",
    "text": "Building an effective chatbot involves understanding various key aspects, including the training of Large Language Models(LLMs), incorporating memory, and production considerations.\n\nTraining\nLanguage models (LLMs) undergo two main phases of training:\n\nPre-training: In this phase, the model learns to predict the next word in a sentence using large-scale datasets. This helps the model acquire general understanding of language.\nFine-tuning: This phase adapts the model to specific tasks. For chat models, the fine-tuning task is typically Conversational, where the model learns to engage in dialogues effectively.\n\n\n\nMemory\nLLMs do not inherently possess memory, meaning they cannot remember previous interactions or conversations. Developers can incorporate memory features to maintain context throughout the interaction.\nFor more insights, see the LangChain course by deeplearning.aion developing chatbots.\n\n\nProduction\nWhen deploying a chatbot to production, it‚Äôs essential to ensure that it provides safe and non-toxic responses.\nFor more details on setting up effective moderation practices, refer to the ‚ÄòModeration‚Äô chapter in the Building Systems with ChatGPT course by deeplearning.ai.\nTo learn more You can find more details about the contents of each course here: Master Chatbot Development with DeepLearning.AI Courses."
  },
  {
    "objectID": "posts/002_chatbot/index.html",
    "href": "posts/002_chatbot/index.html",
    "title": "Chatbot for a Pizza Restaurant using free Gemini LLM API",
    "section": "",
    "text": "This project focuses on developing an order bot for a pizza restaurant using the Gemini 1.5 Flash LLM. Our goal was to create a chatbot that efficiently streamlines customer orders through a user-friendly GUI, which we built using the open-source Python library Panel. To implement this solution, we utilized the free tier of the Gemini API, ensuring cost-effectiveness while maintaining functionality.\nA chatbot project can help solidify our understanding of a few key Gen-AI concepts‚Äì and is fun to build!\n\nMajor Implementation Aspects\n\nLLM API\n\nThe Gemini API key can be obtained here.\nTo get started with the Gemini API, refer to the Gemini API Quickstart Guide.\nGemini‚Äôs ChatSession class supports multi-turn, freeform conversations, enabling dynamic interactions with the chatbot.\n\n\n\nChat GUI\n\nThe ‚ÄòChatInterface‚Äô component of Panel library was used to build the chatbot‚Äôs graphical user interface (GUI).\n\n\n\n\nProblem Statement\nBuild a pizzeria chatbot to facilitate order taking using the Gemini 1.5 Flash model and design its GUI with the Panel library.\n\n\nTasks\n\nConfiguration: import necessary LLM libraries and api key\nPrompt Engineering: Prepare detailed system instructions to steer the behavior of the LLM model.\nDeveloping a Function for Interactions: Create a function that receives prompts, passes them to the LLM, and returns the response while ensuring that the chat context is preserved. This can be achieved using the ChatSession class of the Gemini API.\nBuilding the GUI: Use the ChatInterface component from Panel to build the chatbot‚Äôs graphical interface.\nApp Deployment: Deploy the application both locally and on a web server.\n\nMore information on each project task can be found in the jupyter notebook preview.\n\n\nCode\nGithub Repository: link\n\n\nChatbot in Action\nHere is a video demonstrating our orderbot in action: \nI deployed the chatbot using Ploomber, however the link may currently be unavailable due to limitations of the free tier.\n\nCloud Deployment Options - Good Resources\n\nList from Panel Official Documentation\nDeploy it using Ploomber\nA blog that outlines how to deploy using Google Cloud Run\n\n\n\n\nKey Takeaways\n\nImportance of Prompt Engineering: Providing detailed and clear instructions significantly improves the performance of LLM models. For example, explicit instructions helped the Gemini model perform comparably to the OpenAI model by reducing errors in mathematical calculations.\nPerformance Comparison: A comparison between the paid OpenAI model, ‚Äúgpt-3.5-turbo‚Äù (code available here), and the free-tier Gemini model, ‚Äúgemini-1.5-flash,‚Äù showed that the OpenAI model generally delivered clearer and more accurate responses. However, the Gemini model‚Äôs performance improved with more detailed instructions.\nTailor-Made Chat Interfaces: We used Panel in our project to build a customizable chat interface. Additionally, other packages and libraries, such as Streamlit and Flask, are also available for creating chat interfaces.\nDeployment Options and Costs: Different deployment services, such as Amazon AWS, Google App Engine, Ploomber, and Hugging Face, come with varying costs, which should be considered when choosing a platform.\n\n\n\nChallenges Encountered\n\nCost of OpenAI API: As the OpenAI API is no longer available for free, we opted for the Gemini LLM API. However, the transition presented its own set of challenges, such as requiring more detailed instructions and inconsistent performance in some tasks.\nInconsistent Mathematical Calculations: When asked to re-check a calculation, the model may produce a different total than previously stated.\n\nSolution: To ensure accuracy, explicitly instruct the model to calculate the sum of all ordered items‚Äô prices when computing the customer‚Äôs total bill.\n\nNeed for Extensive Instructions: The Gemini model required more detailed instructions compared to the OpenAI API. For example:\n\nInstruct the chatbot to calculate the total bill by summing up the prices of all ordered items.\nInstruct the chatbot not to suggest dishes not listed in the provided menu.\n\nMissed Prompts for Toppings: Despite instructions to always inquire about toppings after a pizza order is placed, the chatbot occasionally fails to do so.\nWarning Message from Gemini Model: A warning message appeared when adding a system instruction during model initialization.\n\nSolution: The warning was resolved by installing the package grpcio==1.60.1.\n\n\n\n\nAdditional Information\n\nKey Aspects of Building a Chatbot\nMaster Chatbot Development with DeepLearning.AI Courses\n\n\n\nExtensions - Ideas\n\nAdd memory to the bot\n\nUse case: Save customers orders so that we can retrieve it if the customer asks.\nEdited: You can see my implemention of a chatbot with memory capability here.\n\nCreate book-suggestion-bot based on reader‚Äôs reading history, genres of interest, and current best-sellers.\n\nIf you have suggestions or ideas to collaborate, please drop an email."
  },
  {
    "objectID": "posts/003_qaDocs_langchain/index.html",
    "href": "posts/003_qaDocs_langchain/index.html",
    "title": "Document-Based Question Answering Chatbot with Memory Using LangChain and LangGraph",
    "section": "",
    "text": "In this project, I explored how memory could be incorporated into a question-answering (QA) system over documents using LangChain and LangGraph, two powerful libraries designed for rapid development of language applications.\n\nProject Overview\nIn this article, I‚Äôll walk you through my recent project, which combines Retrieval-Augmented Generation (RAG) pipelines with memory integration. Here, the chatbot not only searches through documents for relevant answers but also retains memory of the ongoing conversation. This is particularly valuable for tasks where users need consistent interactions, such as customer support, educational assistance, or domain-specific inquiries.\n\n\nProblem Statement\nBuild a chatbot that answers user queries based on an uploaded document, with memory to maintain context across interactions.\n\n\nTools and Technologies Used\nLangChain: Provides tools for building language model-driven applications, including powerful utilities for working with RAG architectures. LangGraph: Complements LangChain by enabling the use of graph databases to store and retrieve contextually relevant data efficiently, optimizing memory integration. RAG Pipeline: Combines retrieval and generation capabilities to source information from documents and provide concise, natural language responses.\n\n\nThe Architecture: RAG Pipeline with Memory\nA Retrieval-Augmented Generation (RAG) pipeline generally consists of two key components:\nRetriever: Searches for relevant information within documents. Generator: Generates a coherent response based on the retrieved information. In this project, I took a step further by incorporating memory into the RAG pipeline, enabling the chatbot to ‚Äúremember‚Äù past queries and responses within a session. This feature enhances response relevance and continuity in multi-turn conversations, where understanding previous interactions is essential.\n\n\nImplementation Details\n\nStep 1: Setting Up the RAG pipeline\n&lt;&lt; add rag diagram and explanation &gt;&gt; &lt;&lt; add langchain code snippet overview : obs &gt;&gt;\n\n\nStep 2: Integrating Memory with LangGraph\nMemory integration is where LangGraph shines. By storing conversation history within a graph database, LangGraph allows the bot to access past interactions and improve its contextual understanding in real-time.\n&lt;&lt; add langgraph details/diagram from obs &gt;&gt;\n\n\n\nCode\nGithub Repository: link\nDirect link to the notebook: &lt;&lt; add if needed &gt;&gt; &lt;&lt; add descp on all imp files if needed &gt;&gt;\n\n\nChatbot in Action\n&lt;&lt; add screenshot &gt;&gt;\n\n\nAdvantages of Memory-Enhanced QA\nIncorporating memory into the RAG pipeline has several benefits:\n\nImproved User Experience: Users experience a natural flow of conversation without needing to rephrase or reintroduce context.\nEnhanced Response Accuracy: Memory allows the bot to build on prior responses, making it ideal for complex query chains.\nUse of Proprietary Databases: RAG over documents enables the chatbot to retrieve answers from proprietary databases without requiring additional training on the data, making it adaptable for secure, domain-specific applications.\n\n\n\nChallenges and Future Improvements\nOne key challenge in implementing memory-enhanced QA systems is selecting the optimal components‚Äîsuch as the language model (LLM), embedding techniques, and vector database. Each choice impacts the system‚Äôs performance, efficiency, and cost. For instance, different LLMs may vary in response quality, while embedding methods and vector databases can influence retrieval speed and accuracy. Moving forward, evaluating and contrasting these components in various contexts could help fine-tune the pipeline for specific requirements.\n\n\nPossible Extensions - Ideas\n\nCompare performance of different language models, embedding techniques, and vector databases for memory-enhanced QA systems across various application contexts.\n\n\n\nCredits\n\nThumbnail credit: Leveraging LLMs on your domain-specific knowledge base\n\nIf you have suggestions or ideas to collaborate, please drop an email."
  },
  {
    "objectID": "posts/001_gan_project/index.html",
    "href": "posts/001_gan_project/index.html",
    "title": "Generate Handwritten Digits Using GAN",
    "section": "",
    "text": "Objective of the Project\nBuild a DC-GAN (Deep Convolutional Generative Adversarial Network) to generate images of handwritten digits.\n\n\nImportant Details\n\nDataset: MNIST handwritten digits dataset (grayscale)\nModel: Generative Adversarial Network (GAN)\nCode available at: https://github.com/aksharasoman/dcgan\nIt can be built in google colab: python-notebook\n\n\n\nOverview\nA Generative Adversarial Network (GAN) model has two major components: a generator and a discriminator. Figure¬†1 gives outline of a GAN model.\n\n\n\n\n\n\nFigure¬†1: Basic GAN architecture\n\n\n\nA generator creates fake samples that mimic the real samples provided to the discriminator network. The discriminator is a binary classifier that evaluates these inputs, determining whether each one is real or fake. The generator‚Äôs objective is to produce fake samples that are so similar to real ones that the discriminator incorrectly identifies them as genuine.\nGAN loss function consists of two parts: generator loss and discriminator loss.\n\n\n\n\n\n\nNoteGAN Training Strategy\n\n\n\nDuring generator training, the discriminator‚Äôs weights are kept constant and are not updated, and vice versa.\n\n\n\n\nImplementation\nThis project can be divided into 7 tasks.\n\nConfigurations\nLoad dataset\nLoad dataset into batches\nCreate discriminator network\nCreate generator network\nCreate loss function & optimizer\nTraining Loop\n\nFor ease of understanding, you may refer to the iPython notebook, where each task is coded in separate sections.\n\n\n\n\n\n\nTipExpected learnings\n\n\n\n\n\n\nWhat is Generative Adversarial Network\nApplications (Current state-of-art performers for these applications)\nWhat is Generator?\nWhat is discriminator?\nUnderstanding architecture\nLoss functions\nHow to generate a fake image using GAN?\nHow to download and transform data in Pytorch?\nHow to calculate input image size for each layer?\nHow to build a GAN model from scratch in pytorch?\nHow to train a Generative Adversarial Network?\n\nHow to train the model on colab with GPU?\nHow to train the model in a remote cluster environment?\n\nChallenges in GAN\n\n\n\n\n\n\nResults Snapshot\n\n\n\n\n\n\n\n\n\n\nDigits generated after the first epoch\n\n\n\n\n\n\n\n\n\n\n\nDigits generated after 15 epochs\n\n\n\n\n\n\n\nReferences\n\nCoursera Guided Project: ‚ÄúDeep Learning with PyTorch : Generative Adversarial Network‚Äù"
  },
  {
    "objectID": "posts/002_chatbot/in_chatbot_courses.html",
    "href": "posts/002_chatbot/in_chatbot_courses.html",
    "title": "Master Chatbot Development with DeepLearning.AI Courses",
    "section": "",
    "text": "A chatbot project can help solidify your understanding of a few key AI concepts‚Äì and is fun to build! While there are numerous short courses available that focus on developing and using chatbot interfaces, this list will offer a solid starting point.\n\nChatGPT Prompt Engineering for Developers : 1 hr\n\nuses OpenAI API\nbest practices of prompt engineering (writing effective prompts)\nshow how LLM APIs can be used for a variety of tasks:\n\nSummarizing (e.g., summarizing user reviews for brevity)\nInferring (e.g., sentiment classification, topic extraction)\nTransforming text (e.g., translation, spelling & grammar correction)\nExpanding (e.g., automatically writing emails)\n\nBuild a custom chatbot (a pizza bot with GUI) ChatGPT Prompt Engineering Course Notes\n\nLangChain for LLM Application Development - DeepLearning.AI : 1 hr : need to invest time to become adept at the langchain framework!\n\nto take your chatbot to next level by\n\nadding memory\nas reasoning agents\nQ&A on proprietary documents\n\n\nBuilding Systems with the ChatGPT API - DeepLearning.AI : 1 hr\n\nBuild a A customer service chatbot\nMultistage prompts: to split complex tasks into a pipeline of subtasks\nEvaluate your LLM inputs and outputs for safety, accuracy, and relevance"
  },
  {
    "objectID": "posts/002_chatbot/v2_gemini-pizza-chatbot_chatInterface.html",
    "href": "posts/002_chatbot/v2_gemini-pizza-chatbot_chatInterface.html",
    "title": "Jupyter Notebook - Building an Orderbot using Gemini API",
    "section": "",
    "text": "Building a Chatbot using Gemini API\n\nTask 0: Configure API key\nThe Python SDK for the Gemini API is contained in the google-generativeai package.\nInstall dependency using: pip install -q -U google-generativeai\nDo not check an API key into your version control system.\n\n\nTask 1: Initialize the model\n\nimport google.generativeai as genai\n\nwith open('gemini_api_key.txt','r') as file: # rename file to 'llm_api_key.txt'\n    API_KEY = file.read()\ngenai.configure(api_key=API_KEY)\n\nUse system instructions to steer the behavior of the model\n\n# Using a context manager to open the file\nwith open('pizzabot_system_instruction.txt', 'r') as file:\n    sys_instr = file.read()\n\n\nmodel=genai.GenerativeModel(\n  model_name=\"gemini-1.5-flash\",\n  system_instruction=sys_instr)\n\n##### 2.1 Initialize the chat\nchat = model.start_chat(history=[])\n\n\n\nTask 2: Receive Prompts and Save Context and Generate chat responses\nChatSession class of gemini enables us to have freeform conversation over multiple turns. We dont have to store conversation history as a list.\nExample: Build an interactive chat\nThe ChatSession.send_message method returns the same GenerateContentResponse type as GenerativeModel.generate_content. It also appends your message and the response to the chat history\n\nimport panel as pn\ndef run_chat(value,user,instance):\n    response = chat.send_message(value)\n    # return f\"{response.text}\"\n    return pn.chat.ChatMessage(response.text, user=\"Pizza Bot\", avatar=\"üêº\")\n\n\n\nTask 3: Build GUI\nHelp: doc\n\npn.extension(\"perspective\")#initialization\n\nchat_bot = pn.chat.ChatInterface(help_text=\"Welcome to Pizza Paradise! What would like to order?\",callback=run_chat,\n                                 max_height=500,max_width=500,show_rerun=False,show_clear=False,\n                                 )\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nChallenges with Gemini model\n\nMaking mistakes in mathematical calculations. When we ask it to re-check the calculation, it may give you a different total than the one it said earlier. ‚Äì&gt; What helped: While calculating the total bill of the customer, calculate the sum of price of all items ordered by the customer.\nCompared to openai api, I had to add more instructions for the chatbot to make it perform satisfactorily. Eg:\n\nWhile calculating the total bill of the customer, calculate the sum of price of all items ordered by the customer.\nPlease do not suggest dishes not in the menu mentioned below.\n\nThe instructions specify that the chatbot should always ask for toppings after a pizza order is placed. However, chatbot has missed it in some instances.\n\n\n\nTask 4: Serving the Notebook\nWe‚Äôll organize our components in a nicely styled template (MaterialTemplate) and mark it .servable() to add it to our served app\n\npn.template.MaterialTemplate(\n    site=\"Panel\",\n    title=\"Order bot of Pizza Paradise!\",\n    main=[chat_bot],\n).servable(); # The ; is needed in the notebook to not display the template. Its not needed in a script\n\nDeploy the app locally:\nRun in terminal:\npanel serve v2_gemini-pizza-chatbot_chatInterface.ipynb --autoreload\n\n\nDeploy in Cloud:\n\nHow can I deploy my app and embed it in my website? : DONE\n\nUse: https://docs.cloud.ploomber.io/en/latest/apps/panel.html\n\n\n\n\nAppendix: System instructions to the model\nYou are OrderBot, an automated service to collect orders for a pizza restaurant. You first greet the customer, then collects the order, and then asks if it‚Äôs a pickup or delivery. You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. If it‚Äôs a delivery, you ask for an address and contact number. When you give the final order summary, calculate the total price incurred by the customer based on the price tag in the menu. While calculating the total bill of the customer, calculate the sum of price of all items ordered by the customer. If the customer asks for any clarifications on the bill total, re-do the calculation and say the result. Finally you collect the payment. Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu. If they choose a pizza, make sure to ask about Toppings. Please do not suggest dishes not in the menu mentioned below. You respond in a short, very conversational friendly style. The menu includes pepperoni pizza 12.95, 10.00, 7.00 cheese pizza 10.95, 9.25, 6.50 eggplant pizza 11.95, 9.75, 6.75 fries 4.50, 3.50 greek salad 7.25 Toppings: extra cheese 2.00, mushrooms 1.50 sausage 3.00 canadian bacon 3.50 AI sauce 1.50 peppers 1.00 Drinks: coke 3.00, 2.00, 1.00 sprite 3.00, 2.00, 1.00 bottled water 5.00"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Jupyter Notebook - Building an Orderbot using Gemini API\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocument-Based Question Answering Chatbot with Memory Using LangChain and LangGraph\n\n\n\nproject\n\ngen-ai\n\nchatbot\n\nLLM\n\nLangChain\n\n\n\n\n\n\n\nAkshara Soman\n\n\nNov 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaster Chatbot Development with DeepLearning.AI Courses\n\n\n\ngen-ai\n\nchatbot\n\nLLM\n\n\n\n\n\n\n\nAkshara Soman\n\n\nAug 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Aspects of Building a Chatbot\n\n\n\ntheory\n\ngen-ai\n\nchatbot\n\nLLM\n\n\n\n\n\n\n\nAkshara Soman\n\n\nAug 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatbot for a Pizza Restaurant using free Gemini LLM API\n\n\n\nproject\n\ngen-ai\n\nchatbot\n\nLLM\n\n\n\n\n\n\n\nAkshara Soman\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate Handwritten Digits Using GAN\n\n\n\nproject\n\ngen-ai\n\nGAN\n\npytorch\n\n\n\n\n\n\n\nAkshara Soman\n\n\nJul 12, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "ml-notes/cnn_cv.html",
    "href": "ml-notes/cnn_cv.html",
    "title": "Attention & Transformers ‚Äî Interview Q&A",
    "section": "",
    "text": "Expand All\n  Collapse All"
  },
  {
    "objectID": "ml-notes/cnn_cv.html#self-attention",
    "href": "ml-notes/cnn_cv.html#self-attention",
    "title": "Attention & Transformers ‚Äî Interview Q&A",
    "section": "Self-Attention",
    "text": "Self-Attention\n\n\nWhat is self-attention?\n\nSelf-attention allows each token in a sequence to weigh the relevance of all other tokens when computing its representation.\nOne-line:\nSelf-attention lets each token dynamically focus on other tokens to model global context.\nTrap:\nConfusing self-attention with cross-attention."
  },
  {
    "objectID": "ml-notes/optimization.html",
    "href": "ml-notes/optimization.html",
    "title": "akshara soman",
    "section": "",
    "text": "Expand All\n  Collapse All\n\n\n\n\n\n\n\n\n\n{{QUESTION}}\n\n{{CORE_ANSWER}}\nOne-line:\n{{ONE_LINE}}"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "A. Soman, Madhavan C. R., K. Sarkar, and S. Ganapathy, An EEG Study On The Brain Representations in Language Learning, IOP Journal on Biomedical Physics and Engineering Express, 5(2), 25041, (2019).\nK. Praveen, A. Gupta, A. Soman and S. Ganapathy, Second Language Transfer Learning in Humans and Machines Using Image Supervision, IEEE ASRU, Dec.¬†2019.\nV. Krishnamohan, A. Soman, A. Gupta and S. Ganapathy, Audiovisual Correspondence Learning in Humans And Machines, Interspeech 2020, Beijing, October 2020.\nA. Soman, P. Ramachandran, and S. Ganapathy, ERP Evidences of Rapid Semantic Learning In Foreign Language Word Comprehension, Frontiers in Neuroscience, 2022. \nA. Soman, V. Sinha, and S. Ganapathy, Enhancing the EEG Speech Match Mismatch Tasks With Word Boundaries. Proc. INTERSPEECH 2023."
  }
]