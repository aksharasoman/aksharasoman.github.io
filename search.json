[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am an electrical engineer specializing in deep learning, signal processing, and their applications in understanding human and machine perception of speech and language. I hold a Ph.D.¬†degree from the Indian Institute of Science (IISc), Bangalore, where I conducted research under the guidance of Prof.¬†Sriram Ganapathy at the LEAP lab.\nBefore my doctoral studies, I worked as a research engineer in the field of image processing at Tata Research Development and Design Center (TRDDC), Pune. My academic journey includes a Master of Technology (MTech) in System Science and Automation (now known as ‚ÄúArtificial Intelligence‚Äù) from IISc Bangalore, and a Bachelor of Technology (B.Tech) in Electronics and Communication (ECE) from the College of Engineering, Trivandrum (CET)."
  },
  {
    "objectID": "posts/002_chatbot/in_keyaspects_chatbot.html",
    "href": "posts/002_chatbot/in_keyaspects_chatbot.html",
    "title": "Key Aspects of Building a Chatbot",
    "section": "",
    "text": "Building an effective chatbot involves understanding various key aspects, including the training of Large Language Models(LLMs), incorporating memory, and production considerations.\n\nTraining\nLanguage models (LLMs) undergo two main phases of training:\n\nPre-training: In this phase, the model learns to predict the next word in a sentence using large-scale datasets. This helps the model acquire general understanding of language.\nFine-tuning: This phase adapts the model to specific tasks. For chat models, the fine-tuning task is typically Conversational, where the model learns to engage in dialogues effectively.\n\n\n\nMemory\nLLMs do not inherently possess memory, meaning they cannot remember previous interactions or conversations. Developers can incorporate memory features to maintain context throughout the interaction.\nFor more insights, see the LangChain course by deeplearning.aion developing chatbots.\n\n\nProduction\nWhen deploying a chatbot to production, it‚Äôs essential to ensure that it provides safe and non-toxic responses.\nFor more details on setting up effective moderation practices, refer to the ‚ÄòModeration‚Äô chapter in the Building Systems with ChatGPT course by deeplearning.ai.\nTo learn more You can find more details about the contents of each course here: Master Chatbot Development with DeepLearning.AI Courses."
  },
  {
    "objectID": "posts/002_chatbot/index.html",
    "href": "posts/002_chatbot/index.html",
    "title": "Chatbot for a Pizza Restaurant using free Gemini LLM API",
    "section": "",
    "text": "This project focuses on developing an order bot for a pizza restaurant using the Gemini 1.5 Flash LLM. Our goal was to create a chatbot that efficiently streamlines customer orders through a user-friendly GUI, which we built using the open-source Python library Panel. To implement this solution, we utilized the free tier of the Gemini API, ensuring cost-effectiveness while maintaining functionality.\nA chatbot project can help solidify our understanding of a few key Gen-AI concepts‚Äì and is fun to build!\n\nMajor Implementation Aspects\n\nLLM API\n\nThe Gemini API key can be obtained here.\nTo get started with the Gemini API, refer to the Gemini API Quickstart Guide.\nGemini‚Äôs ChatSession class supports multi-turn, freeform conversations, enabling dynamic interactions with the chatbot.\n\n\n\nChat GUI\n\nThe ‚ÄòChatInterface‚Äô component of Panel library was used to build the chatbot‚Äôs graphical user interface (GUI).\n\n\n\n\nProblem Statement\nBuild a pizzeria chatbot to facilitate order taking using the Gemini 1.5 Flash model and design its GUI with the Panel library.\n\n\nTasks\n\nConfiguration: import necessary LLM libraries and api key\nPrompt Engineering: Prepare detailed system instructions to steer the behavior of the LLM model.\nDeveloping a Function for Interactions: Create a function that receives prompts, passes them to the LLM, and returns the response while ensuring that the chat context is preserved. This can be achieved using the ChatSession class of the Gemini API.\nBuilding the GUI: Use the ChatInterface component from Panel to build the chatbot‚Äôs graphical interface.\nApp Deployment: Deploy the application both locally and on a web server.\n\nMore information on each project task can be found in the jupyter notebook preview.\n\n\nCode\nGithub Repository: link\n\n\nChatbot in Action\nHere is a video demonstrating our orderbot in action: \nI deployed the chatbot using Ploomber, however the link may currently be unavailable due to limitations of the free tier.\n\nCloud Deployment Options - Good Resources\n\nList from Panel Official Documentation\nDeploy it using Ploomber\nA blog that outlines how to deploy using Google Cloud Run\n\n\n\n\nKey Takeaways\n\nImportance of Prompt Engineering: Providing detailed and clear instructions significantly improves the performance of LLM models. For example, explicit instructions helped the Gemini model perform comparably to the OpenAI model by reducing errors in mathematical calculations.\nPerformance Comparison: A comparison between the paid OpenAI model, ‚Äúgpt-3.5-turbo‚Äù (code available here), and the free-tier Gemini model, ‚Äúgemini-1.5-flash,‚Äù showed that the OpenAI model generally delivered clearer and more accurate responses. However, the Gemini model‚Äôs performance improved with more detailed instructions.\nTailor-Made Chat Interfaces: We used Panel in our project to build a customizable chat interface. Additionally, other packages and libraries, such as Streamlit and Flask, are also available for creating chat interfaces.\nDeployment Options and Costs: Different deployment services, such as Amazon AWS, Google App Engine, Ploomber, and Hugging Face, come with varying costs, which should be considered when choosing a platform.\n\n\n\nChallenges Encountered\n\nCost of OpenAI API: As the OpenAI API is no longer available for free, we opted for the Gemini LLM API. However, the transition presented its own set of challenges, such as requiring more detailed instructions and inconsistent performance in some tasks.\nInconsistent Mathematical Calculations: When asked to re-check a calculation, the model may produce a different total than previously stated.\n\nSolution: To ensure accuracy, explicitly instruct the model to calculate the sum of all ordered items‚Äô prices when computing the customer‚Äôs total bill.\n\nNeed for Extensive Instructions: The Gemini model required more detailed instructions compared to the OpenAI API. For example:\n\nInstruct the chatbot to calculate the total bill by summing up the prices of all ordered items.\nInstruct the chatbot not to suggest dishes not listed in the provided menu.\n\nMissed Prompts for Toppings: Despite instructions to always inquire about toppings after a pizza order is placed, the chatbot occasionally fails to do so.\nWarning Message from Gemini Model: A warning message appeared when adding a system instruction during model initialization.\n\nSolution: The warning was resolved by installing the package grpcio==1.60.1.\n\n\n\n\nAdditional Information\n\nKey Aspects of Building a Chatbot\nMaster Chatbot Development with DeepLearning.AI Courses\n\n\n\nExtensions - Ideas\n\nAdd memory to the bot\n\nUse case: Save customers orders so that we can retrieve it if the customer asks.\n\nCreate book-suggestion-bot based on reader‚Äôs reading history, genres of interest, and current best-sellers.\n\nIf you have suggestions or ideas to collaborate, please drop an email."
  },
  {
    "objectID": "posts/coding-practice/questions_list.html",
    "href": "posts/coding-practice/questions_list.html",
    "title": "List of Coding Questions & Solutions",
    "section": "",
    "text": "A full list of the topics and questions covered in this repo (so far).\n\nAugust Week 1 : Solutions counter - 0/75\n\n\n\n\n\n\nLeetcode Link\nSolution\nRemarks\n\n\n\n\nFind Minimum in Rotated Sorted Array\nmin_in_rotated_array.py"
  },
  {
    "objectID": "posts/coding-practice/questions_list.html#binary-search",
    "href": "posts/coding-practice/questions_list.html#binary-search",
    "title": "List of Coding Questions & Solutions",
    "section": "",
    "text": "Leetcode Link\nSolution\nRemarks\n\n\n\n\nFind Minimum in Rotated Sorted Array\nmin_in_rotated_array.py"
  },
  {
    "objectID": "posts/001_gan_project/index.html",
    "href": "posts/001_gan_project/index.html",
    "title": "Generate Handwritten Digits Using GAN",
    "section": "",
    "text": "Objective of the Project\nBuild a DC-GAN (Deep Convolutional Generative Adversarial Network) to generate images of handwritten digits.\n\n\nImportant Details\n\nDataset: MNIST handwritten digits dataset (grayscale)\nModel: Generative Adversarial Network (GAN)\nCode available at: https://github.com/aksharasoman/dcgan\nIt can be built in google colab: python-notebook\n\n\n\nOverview\nA Generative Adversarial Network (GAN) model has two major components: a generator and a discriminator. Figure¬†1 gives outline of a GAN model.\n\n\n\n\n\n\nFigure¬†1: Basic GAN architecture\n\n\n\nA generator creates fake samples that mimic the real samples provided to the discriminator network. The discriminator is a binary classifier that evaluates these inputs, determining whether each one is real or fake. The generator‚Äôs objective is to produce fake samples that are so similar to real ones that the discriminator incorrectly identifies them as genuine.\nGAN loss function consists of two parts: generator loss and discriminator loss.\n\n\n\n\n\n\nGAN Training Strategy\n\n\n\nDuring generator training, the discriminator‚Äôs weights are kept constant and are not updated, and vice versa.\n\n\n\n\nImplementation\nThis project can be divided into 7 tasks.\n\nConfigurations\nLoad dataset\nLoad dataset into batches\nCreate discriminator network\nCreate generator network\nCreate loss function & optimizer\nTraining Loop\n\nFor ease of understanding, you may refer to the iPython notebook, where each task is coded in separate sections.\n\n\n\n\n\n\nExpected learnings\n\n\n\n\n\n\nWhat is Generative Adversarial Network\nApplications (Current state-of-art performers for these applications)\nWhat is Generator?\nWhat is discriminator?\nUnderstanding architecture\nLoss functions\nHow to generate a fake image using GAN?\nHow to download and transform data in Pytorch?\nHow to calculate input image size for each layer?\nHow to build a GAN model from scratch in pytorch?\nHow to train a Generative Adversarial Network?\n\nHow to train the model on colab with GPU?\nHow to train the model in a remote cluster environment?\n\nChallenges in GAN\n\n\n\n\n\n\nResults Snapshot\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigits generated after the first epoch\n\n\n\n\n\n\n\n\n\n\n\nDigits generated after 15 epochs\n\n\n\n\n\n\n\nReferences\n\nCoursera Guided Project: ‚ÄúDeep Learning with PyTorch : Generative Adversarial Network‚Äù"
  },
  {
    "objectID": "posts/coding-practice/index.html",
    "href": "posts/coding-practice/index.html",
    "title": "Coding Practice - Solution to Leetcode Problems",
    "section": "",
    "text": "This is a collection of solutions_(in progress)_ to common Leetcode questions, based on a list compiled by Neetcode.\nThe solutions are in Python3. Required explanations are provided as comments within the script file. If more detailed explanations are necessary, they will be included in an accompanying markdown file.\n\nYou can find the list of questions that are covered in this repo here\n\nI recommend the following line-of-action if you are attempting a problem for the FIRST time:\n\n\n\nneetcode-sop\n\n\n\n\nIf you face any issues or have any suggestions, please feel free to open an issue in the github repo. I will try to get back to you as soon as possible.\n\n\n\nIf you want to contact me, you can reach me via email or visit my website."
  },
  {
    "objectID": "posts/coding-practice/index.html#issues",
    "href": "posts/coding-practice/index.html#issues",
    "title": "Coding Practice - Solution to Leetcode Problems",
    "section": "",
    "text": "If you face any issues or have any suggestions, please feel free to open an issue in the github repo. I will try to get back to you as soon as possible."
  },
  {
    "objectID": "posts/coding-practice/index.html#more-questions",
    "href": "posts/coding-practice/index.html#more-questions",
    "title": "Coding Practice - Solution to Leetcode Problems",
    "section": "",
    "text": "If you want to contact me, you can reach me via email or visit my website."
  },
  {
    "objectID": "posts/002_chatbot/in_chatbot_courses.html",
    "href": "posts/002_chatbot/in_chatbot_courses.html",
    "title": "Master Chatbot Development with DeepLearning.AI Courses",
    "section": "",
    "text": "A chatbot project can help solidify your understanding of a few key AI concepts‚Äì and is fun to build! While there are numerous short courses available that focus on developing and using chatbot interfaces, this list will offer a solid starting point.\n\nChatGPT Prompt Engineering for Developers : 1 hr\n\nuses OpenAI API\nbest practices of prompt engineering (writing effective prompts)\nshow how LLM APIs can be used for a variety of tasks:\n\nSummarizing (e.g., summarizing user reviews for brevity)\nInferring (e.g., sentiment classification, topic extraction)\nTransforming text (e.g., translation, spelling & grammar correction)\nExpanding (e.g., automatically writing emails)\n\nBuild a custom chatbot (a pizza bot with GUI) ChatGPT Prompt Engineering Course Notes\n\nLangChain for LLM Application Development - DeepLearning.AI : 1 hr : need to invest time to become adept at the langchain framework!\n\nto take your chatbot to next level by\n\nadding memory\nas reasoning agents\nQ&A on proprietary documents\n\n\nBuilding Systems with the ChatGPT API - DeepLearning.AI : 1 hr\n\nBuild a A customer service chatbot\nMultistage prompts: to split complex tasks into a pipeline of subtasks\nEvaluate your LLM inputs and outputs for safety, accuracy, and relevance"
  },
  {
    "objectID": "posts/002_chatbot/v2_gemini-pizza-chatbot_chatInterface.html",
    "href": "posts/002_chatbot/v2_gemini-pizza-chatbot_chatInterface.html",
    "title": "Jupyter Notebook - Building an Orderbot using Gemini API",
    "section": "",
    "text": "Building a Chatbot using Gemini API\n\nTask 0: Configure API key\nThe Python SDK for the Gemini API is contained in the google-generativeai package.\nInstall dependency using: pip install -q -U google-generativeai\nDo not check an API key into your version control system.\n\n\nTask 1: Initialize the model\n\nimport google.generativeai as genai\n\nwith open('gemini_api_key.txt','r') as file: # rename file to 'llm_api_key.txt'\n    API_KEY = file.read()\ngenai.configure(api_key=API_KEY)\n\nUse system instructions to steer the behavior of the model\n\n# Using a context manager to open the file\nwith open('pizzabot_system_instruction.txt', 'r') as file:\n    sys_instr = file.read()\n\n\nmodel=genai.GenerativeModel(\n  model_name=\"gemini-1.5-flash\",\n  system_instruction=sys_instr)\n\n##### 2.1 Initialize the chat\nchat = model.start_chat(history=[])\n\n\n\nTask 2: Receive Prompts and Save Context and Generate chat responses\nChatSession class of gemini enables us to have freeform conversation over multiple turns. We dont have to store conversation history as a list.\nExample: Build an interactive chat\nThe ChatSession.send_message method returns the same GenerateContentResponse type as GenerativeModel.generate_content. It also appends your message and the response to the chat history\n\nimport panel as pn\ndef run_chat(value,user,instance):\n    response = chat.send_message(value)\n    # return f\"{response.text}\"\n    return pn.chat.ChatMessage(response.text, user=\"Pizza Bot\", avatar=\"üêº\")\n\n\n\nTask 3: Build GUI\nHelp: doc\n\npn.extension(\"perspective\")#initialization\n\nchat_bot = pn.chat.ChatInterface(help_text=\"Welcome to Pizza Paradise! What would like to order?\",callback=run_chat,\n                                 max_height=500,max_width=500,show_rerun=False,show_clear=False,\n                                 )\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nChallenges with Gemini model\n\nMaking mistakes in mathematical calculations. When we ask it to re-check the calculation, it may give you a different total than the one it said earlier. ‚Äì&gt; What helped: While calculating the total bill of the customer, calculate the sum of price of all items ordered by the customer.\nCompared to openai api, I had to add more instructions for the chatbot to make it perform satisfactorily. Eg:\n\nWhile calculating the total bill of the customer, calculate the sum of price of all items ordered by the customer.\nPlease do not suggest dishes not in the menu mentioned below.\n\nThe instructions specify that the chatbot should always ask for toppings after a pizza order is placed. However, chatbot has missed it in some instances.\n\n\n\nTask 4: Serving the Notebook\nWe‚Äôll organize our components in a nicely styled template (MaterialTemplate) and mark it .servable() to add it to our served app\n\npn.template.MaterialTemplate(\n    site=\"Panel\",\n    title=\"Order bot of Pizza Paradise!\",\n    main=[chat_bot],\n).servable(); # The ; is needed in the notebook to not display the template. Its not needed in a script\n\nDeploy the app locally:\nRun in terminal:\npanel serve v2_gemini-pizza-chatbot_chatInterface.ipynb --autoreload\n\n\nDeploy in Cloud:\n\nHow can I deploy my app and embed it in my website? : DONE\n\nUse: https://docs.cloud.ploomber.io/en/latest/apps/panel.html\n\n\n\n\nAppendix: System instructions to the model\nYou are OrderBot, an automated service to collect orders for a pizza restaurant. You first greet the customer, then collects the order, and then asks if it‚Äôs a pickup or delivery. You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. If it‚Äôs a delivery, you ask for an address and contact number. When you give the final order summary, calculate the total price incurred by the customer based on the price tag in the menu. While calculating the total bill of the customer, calculate the sum of price of all items ordered by the customer. If the customer asks for any clarifications on the bill total, re-do the calculation and say the result. Finally you collect the payment. Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu. If they choose a pizza, make sure to ask about Toppings. Please do not suggest dishes not in the menu mentioned below. You respond in a short, very conversational friendly style. The menu includes pepperoni pizza 12.95, 10.00, 7.00 cheese pizza 10.95, 9.25, 6.50 eggplant pizza 11.95, 9.75, 6.75 fries 4.50, 3.50 greek salad 7.25 Toppings: extra cheese 2.00, mushrooms 1.50 sausage 3.00 canadian bacon 3.50 AI sauce 1.50 peppers 1.00 Drinks: coke 3.00, 2.00, 1.00 sprite 3.00, 2.00, 1.00 bottled water 5.00"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "akshara soman",
    "section": "",
    "text": "Jupyter Notebook - Building an Orderbot using Gemini API\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaster Chatbot Development with DeepLearning.AI Courses\n\n\n\ngen-ai\n\n\nchatbot\n\n\nLLM\n\n\n\n\n\n\n\nAkshara Soman\n\n\nAug 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Aspects of Building a Chatbot\n\n\n\ntheory\n\n\ngen-ai\n\n\nchatbot\n\n\nLLM\n\n\n\n\n\n\n\nAkshara Soman\n\n\nAug 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatbot for a Pizza Restaurant using free Gemini LLM API\n\n\n\nproject\n\n\ngen-ai\n\n\nchatbot\n\n\nLLM\n\n\n\n\n\n\n\nAkshara Soman\n\n\nAug 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCoding Practice - Solution to Leetcode Problems\n\n\n\ncoding\n\n\n\n\n\n\n\nAkshara Soman\n\n\nAug 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate Handwritten Digits Using GAN\n\n\n\nproject\n\n\ngen-ai\n\n\nGAN\n\n\npytorch\n\n\n\n\n\n\n\nAkshara Soman\n\n\nJul 12, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  }
]